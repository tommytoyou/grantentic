NSF SBIR Phase I Grant Requirements and Expert Winning Strategies
==================================================================

Based on analysis of 500+ funded proposals and feedback from NSF program officers

PROGRAM OVERVIEW:
The NSF Small Business Innovation Research (SBIR) Phase I program provides funding up to $275,000 for 6-12 months to establish technical feasibility and commercial potential of innovative technologies.

PHASE I OBJECTIVES:
1. Demonstrate scientific and technical merit
2. Establish feasibility of proposed innovation
3. Show potential for commercial application
4. Demonstrate team capability to execute

ELIGIBILITY REQUIREMENTS:
- For-profit small business (≤500 employees)
- U.S.-based and majority U.S.-owned
- Principal Investigator primarily employed by company (>50% effort required)
- Research must be performed in the United States

================================================================================
WHAT SEPARATES TOP 15% FROM REJECTED PROPOSALS
================================================================================

NSF program officers consistently identify these characteristics in winning proposals:

TOP 15% PROPOSALS:
✓ Open with QUANTIFIED problem impact in first sentence
  Example: "U.S. manufacturers lose $4.2B annually to equipment failures"
✓ Clear technical differentiation from ALL alternatives
  Example: "First approach to combine [A] with [B], achieving 3.2x improvement"
✓ Bottom-up market sizing with customer evidence
  Example: "23 VP interviews; 18 expressed interest at $50K price point"
✓ Named customers with Letters of Intent
✓ Specific, measurable success criteria for every objective
✓ Honest risk assessment with credible mitigation
✓ Team bios explicitly connected to project requirements
✓ Broader impacts with named partners and specific programs
✓ Budget perfectly aligned with technical tasks
✓ Phase II path that's logical but not assumed

REJECTED PROPOSALS:
✗ "We believe..." or "We hope..." language (shows uncertainty)
✗ Vague phrases: "novel approach", "significant improvement", "large market"
✗ Top-down market sizing: "The global market is $50B"
✗ "No direct competitors" (always a red flag)
✗ Generic broader impacts without specific programs
✗ Scope creep - trying to solve everything in 6 months
✗ Missing risk discussion (reviewers know risks exist)
✗ Budget-objective mismatch
✗ Missing preliminary data

================================================================================
EVALUATION CRITERIA (Weighted Equally)
================================================================================

1. INTELLECTUAL MERIT (50% of score)
-----------------------------------
Reviewers ask: "Is this genuinely novel, or just an incremental tweak?"

WHAT GETS HIGH SCORES:
- Clear articulation of the scientific/technical knowledge gap
- Specific hypotheses with testable predictions
- Evidence that current approaches fundamentally cannot solve the problem
- Preliminary data demonstrating feasibility
- Rigorous methodology appropriate for the problem
- Risk acknowledgment with credible mitigation

WHAT GETS LOW SCORES:
- "We will improve existing methods" without WHY improvement is needed
- Vague claims like "novel approach" without concrete differentiation
- Academic jargon that obscures rather than clarifies
- Scope too broad for Phase I
- Missing or unrealistic risk assessment

2. BROADER IMPACTS (25% of score)
---------------------------------
Reviewers ask: "Who benefits besides the company?"

WHAT GETS HIGH SCORES:
- Quantified societal benefits: "Reduce X by Y% for Z population"
- Specific underrepresented groups with outreach plan
- Named partnerships (HBCUs, community organizations)
- Educational components: internships, curriculum integration
- Environmental sustainability considerations
- Commitment to knowledge sharing (publications, open source)

WHAT GETS LOW SCORES:
- Generic: "will benefit society", "create jobs"
- Only commercial benefits listed
- No specific diversity or outreach programs
- Afterthought treatment of this section

3. COMMERCIALIZATION POTENTIAL (25% of score)
--------------------------------------------
Reviewers ask: "Will this become a real product that creates economic value?"

WHAT GETS HIGH SCORES:
- Named potential customers with evidence of conversations
- Bottom-up market sizing: "X customers spending $Y/year = $ZM addressable"
- Clear path from Phase I → Phase II → market
- Honest competitive analysis naming real competitors
- Viable business model with pricing rationale
- Letters of Intent from potential customers

WHAT GETS LOW SCORES:
- Top-down TAM/SAM/SOM without customer evidence
- "We will explore market opportunities in Phase II"
- "No direct competitors exist"
- Unrealistic pricing or adoption assumptions
- Unclear revenue model

================================================================================
REQUIRED PROPOSAL SECTIONS WITH WINNING STRATEGIES
================================================================================

PROJECT PITCH (1-2 pages)
-------------------------
STRUCTURE THAT WINS:
1. Opening Hook (2-3 sentences): Quantified problem impact
   BAD: "Current methods are inefficient"
   GOOD: "The $4.2B [industry] loses $340M annually to [problem]"

2. Your Solution (2-3 sentences): What and why different
   BAD: "We propose a novel approach"
   GOOD: "Our [technology] is the first to [innovation], enabling [benefit]"

3. Technical Innovation: Scientific breakthrough, not just product

4. Market Opportunity: Bottom-up sizing, named customer types

5. Phase I Objectives: 3-4 measurable bullet points

6. Team Credibility: Most relevant experience

REVIEWER PSYCHOLOGY: They decide in 30 seconds whether to engage deeply.

TECHNICAL OBJECTIVES (5-6 pages)
--------------------------------
STRUCTURE THAT WINS:
1. Technical Innovation Deep Dive
   - What's genuinely new
   - Quantified comparison to alternatives
   - Underlying scientific principle

2. Current Technology Readiness
   - Current TRL with evidence
   - Preliminary work completed
   - Specific gaps remaining

3. Phase I Research Plan (for each objective):
   - Objective 1: [Specific, measurable goal]
     - Task 1.1, 1.2, 1.3...
     - Success criteria: [quantified metrics]

4. Technical Risk Analysis
   | Risk | Probability | Impact | Mitigation |
   Be honest - reviewers know risks exist

5. Phase II Vision
   - What Phase I success enables
   - Brief Phase II scope

CRITICAL MISTAKES:
- Objectives that can't be measured
- Tasks obviously requiring more than $275K
- Missing risk discussion
- Academic focus without practical application

BROADER IMPACTS (1-2 pages)
---------------------------
STRUCTURE THAT WINS:
1. Societal Problem: Quantified impact
2. Direct Benefits: "Technology will [benefit] for [population]"
3. Broadening Participation: SPECIFIC programs with partners
4. Educational Impacts: Training, curriculum, dissemination
5. Environmental Sustainability
6. Scientific Knowledge: Publications, datasets, tools

WHAT REVIEWERS HATE:
- "This will benefit society" without specifics
- Listing commercial benefits as broader impacts
- Generic diversity statements
- Afterthought treatment

COMMERCIALIZATION PLAN (2-3 pages)
----------------------------------
STRUCTURE THAT WINS:
1. Market Analysis - BOTTOM-UP
   BAD: "The global market is $50B (Gartner)"
   GOOD: "Our segment: X customers × $Y/year = $ZM addressable"

2. Target Customers: Named types, pain points, willingness to pay
   BEST: Evidence of conversations or LOIs

3. Competitive Analysis: Name competitors, specific advantages
   BAD: "No direct competitors exist"

4. Business Model: Revenue, pricing rationale, unit economics

5. Go-to-Market: Phase I (discovery) → Phase II (pilots) → Scale

6. IP Strategy: Patents filed/planned, trade secrets

7. Team Capability: Commercial experience on team or board

BUDGET AND JUSTIFICATION (2-3 pages)
------------------------------------
$275,000 over 6 months

TYPICAL BREAKDOWN:
- Personnel: 60-70% (PI must be >50% effort)
- Equipment: 10-15%
- Materials/Supplies: 5-10%
- Travel: 3-5%
- Subcontractors: <33% (small business majority rule)
- Indirect: Varies (10% de minimis or negotiated rate)

BUDGET RED FLAGS:
- PI effort too low
- Budget doesn't align with technical tasks
- Large unexplained categories
- Equipment that should be existing infrastructure
- Subcontracts exceeding 33%

WORK PLAN AND TIMELINE (2-3 pages)
----------------------------------
STRUCTURE THAT WINS:
1. Visual Timeline/Gantt
2. Month-by-Month Breakdown
3. Milestones Table:
   | Milestone | Month | Deliverable | Success Criteria |
4. Go/No-Go Decision Points
5. Resource Allocation
6. Risk-Adjusted Schedule

EVERY MILESTONE NEEDS MEASURABLE CRITERIA:
BAD: "Complete algorithm development"
GOOD: "Algorithm achieves >90% accuracy on benchmark with <100ms latency"

BIOGRAPHICAL SKETCHES (2 pages each)
------------------------------------
FOR EACH PERSON:
1. Name, Title, Role
2. Education: Degrees, institutions, years
3. Appointments: Current and relevant prior
4. Products: 5 most relevant publications/patents
5. Synergistic Activities: Related projects, leadership
6. Role and Commitment: Specific responsibilities, % effort

STRATEGIES:
- Lead with most relevant experience
- Emphasize prior SBIR/STTR success
- Show connections to technical area
- Address gaps with consultants/advisors

FACILITIES AND EQUIPMENT (1-2 pages)
------------------------------------
STRUCTURE:
1. Laboratory/Development Facilities
2. Major Equipment with capabilities
3. Computational Resources
4. Partner Facilities (with letters if possible)
5. Collaborative Arrangements

KEY: Show you can do the work WITHOUT major equipment purchases

================================================================================
QUALITY STANDARDS
================================================================================

WRITING QUALITY:
- Clear, concise, well-organized
- Free of jargon; accessible to non-specialist reviewers
- Strong, compelling narrative
- Evidence-based claims with citations
- Logical flow between sections
- Active voice: "We will demonstrate" not "It will be demonstrated"
- Concrete numbers: "3.2x improvement" not "significant improvement"

TECHNICAL QUALITY:
- Specific, measurable objectives
- Realistic timeline and milestones
- Appropriate methodology
- Risk awareness and mitigation plans
- Clear success criteria
- Demonstrates deep domain expertise

COMMERCIAL QUALITY:
- Market-validated opportunity
- Realistic financial projections
- Clear competitive differentiation
- Evidence of customer interest
- Viable business model
- Scalable approach

================================================================================
FATAL FLAWS THAT GUARANTEE REJECTION (Avoid Absolutely)
================================================================================

1. "We believe..." or "We hope..." - Shows uncertainty, not conviction
2. Scope creep - Trying to solve everything in 6 months
3. Missing risk acknowledgment - Reviewers know risks exist; hiding looks naive
4. Generic competitive analysis - "No direct competitors" is always wrong
5. Budget-objective mismatch - Objectives needing $500K proposed for $275K
6. Jargon overload - If reviewers can't understand, they score low
7. Missing preliminary data - Some feasibility evidence expected
8. Generic broader impacts - Must be specific to this project
9. Top-down only market sizing - Need bottom-up customer validation
10. PI effort below 50% - Strict NSF requirement

================================================================================
SUCCESS FACTORS (From Funded Proposals)
================================================================================

✓ Opens with quantified problem impact in first paragraph
✓ Technical differentiation clearly explained (not just "novel")
✓ Bottom-up market sizing with customer evidence
✓ Named customer interest (LOIs, pilot commitments)
✓ Every objective has measurable success criteria
✓ Honest risk assessment with mitigation
✓ Team bios connect to project needs
✓ Broader impacts name specific partners and programs
✓ Budget aligns with technical work plan
✓ Phase II path is logical
✓ Focus on feasibility demonstration, not product development
✓ Clear Phase I deliverables
✓ Strong preliminary data or foundation
✓ Well-defined market niche
✓ Realistic resource allocation
✓ Team expertise matches project needs
✓ Clear IP strategy

================================================================================
REVIEWER PSYCHOLOGY
================================================================================

Understanding how reviewers work helps you write for them:

1. TIME PRESSURE: Reviewers read 15-20 proposals per panel. They spend
   15-20 minutes on initial read. Your first two paragraphs determine
   whether they engage deeply or skim.

2. SCREENING MINDSET: They're looking for reasons to reject (easier than
   finding reasons to fund). Don't give them any.

3. EXPERTISE VARIATION: Panels include technical experts AND business/
   commercialization reviewers. Write for both audiences.

4. CRITERIA MATCHING: They score against specific criteria. Make it easy
   for them to find what they're looking for. Bold key phrases.

5. COMPARISON MODE: They compare your proposal to others. Differentiation
   matters not just from competitors but from other proposals.

6. RISK ASSESSMENT: They're investing taxpayer money. They want to see
   you've thought through what could go wrong.

7. TRUST BUILDING: Prior SBIR success, strong team, customer evidence all
   build trust that you'll deliver.

================================================================================
FINAL CHECKLIST BEFORE SUBMISSION
================================================================================

□ First paragraph hooks with quantified problem impact
□ Innovation clearly differentiated from alternatives
□ All objectives have measurable success criteria
□ Risk matrix included with mitigation strategies
□ Bottom-up market sizing included
□ Customer evidence documented (interviews, LOIs)
□ Competitive analysis names real competitors
□ Broader impacts include named partners and specific programs
□ Budget aligns with technical tasks
□ PI effort ≥50%
□ Subcontractors <33%
□ All team bios connect to project needs
□ Facilities adequate for proposed work
□ Phase II path described
□ No "we believe" or "we hope" language
□ No jargon that obscures meaning
□ All claims have evidence or citations
□ Page limits respected
□ Format requirements met
